#data merge를 위하여, 일시와 시간대를 분리
weather['time']<-substring(weather$일시,11,13)
weather$일시<-substring(weather$일시,0,10)
weather$일시<-as.Date(weather$일시)
weather$time<-as.integer(weather$time)

# 실제 측정 데이터이기 때문에, 12시 이전의 시간대만 사용
weather2<-subset(weather,time>= 6 & time<12)

train2 = train2[-which(duplicated(train2$id)),]#id 기준으로 중복제거 

sample_train2<-sample_frac(train2,0.1) 10% 사용

#최적의 파라미터 찾기
ntree<-c(400,500,600)
mtry<-c(2:4)
param<-data.frame(n=ntree,m=mtry)
param
for(i in param$n){
  cat('ntree=',i,'\n')
  for(j in param$m){
    cat('mtry')
    model_train<- randomForest(input_var, data=sample_train2, ntree=i,mtry=j,
                               na.action=na.omit)
    print(model_train)
  }
}
model_train


all:
 randomForest(formula = input_var, data = sample_train2, ntree = which.min(random$mse)) 
               Type of random forest: regression
                     Number of trees: 165
No. of variables tried at each split: 13

          Mean of squared residuals: 12.35664
                    % Var explained: 47.26
> random

Call:
 randomForest(formula = input_var, data = sample_train2, importance = T) 
               Type of random forest: regression
                     Number of trees: 500
No. of variables tried at each split: 13

          Mean of squared residuals: 12.55291
                    % Var explained: 46.42


 결과는 MSE 약 0.68, 설명 분산 explained variance 는 약 53% 임을 알수 있다. 

#ROC 
set.seed(1217)
probs <- runif(100)
labels <- as.factor(ifelse(probs > .5 & runif(100) < .4, "A","B"))
pred <- prediction(probs,labels)
plot(performance(pred, "tpr", "fpr")))
#reg