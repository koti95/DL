install.packages(c("rvest","httr","KoNLP","stringr","tm","ggraph","xml2"))
library(rvest)
library(httr)
library(KoNLP)
library(stringr)
library(tm)
library(ggraph)
library(xml2)

url_base <- 'http://movie.daum.net/moviedb/grade?movieId=90524&type=netizen&page='

all.reviews1 <-c()
for(page in 1:10){
  url<-paste(url_base, page,sep="")
  htxt <- read_html(url)%>% html_nodes(".desc_review") %>%  html_text()              
  reviews <-repair_encoding(htxt, from='utf-8')      
 if (length(reviews)==0){break}                    # 리부가 없는 부분 제거                       
 reviews <- str_trim(reviews)                      # 앞 뒤 공백문자 제거     
 all.reviews1 <-c(all.reviews1,reviews)
}
all.reviews1 <- all.reviews1[!str_detect(all.reviews1,"평점")]  # 수집에 불필요한 단어가 포함된 내용 제거

write.csv(all.reviews1,"c:/data/MOVIE_90524_1.csv")

