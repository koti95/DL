install.packages("nnet")
install.packages("caret")
install.packages("stringi")
install.packages("ROCR")
library(dplyr) # dplyr 패키지 로드
                 
library(nnet)
library(caret)
library(stringi)
library(ROCR)

#데이터 입력 
setwd("c:/deep1")
KOSPI<- read.csv("c:/deep1/KOSPI.csv", stringsAsFactors=FALSE)
ECONOMIC <-read.csv("c:/deep1/ECONOMIC.csv", stringsAsFactors=FALSE)
EXCHANGE <-read.csv("c:/deep1/EXCHANGE.csv", stringsAsFactors=FALSE)
MARKET <-read.csv("c:/deep1/MARKET.csv", stringsAsFactors=FALSE)
PER <-read.csv("c:/deep1/PER.csv", stringsAsFactors=FALSE)
KOS<-merge(KOSPI, ECONOMIC, by="날짜", all.x=TRUE)
KOS<-merge(KOS, EXCHANGE, by="날짜", all.x=TRUE)
KOS<-merge(KOS, MARKET, by="날짜", all.x=TRUE)
KOS<-merge(KOS, PER, by="날짜", all.x=TRUE)

#데이터 탐색 및 변환 
is.na(KOS)
str(KOS)
KOSPI<- KOSPI[,-1]#날짜 제거
KOSPI$Y <- factor(KOSPI$Y) #팩터로 변환 

KOSPI
str(ECONOMIC)
str(EXCHANGE)
str(MARKET)
str(PER)

#결측값 탐색, 결측치 평균대치법으로 대체
colSums(is.na(new))#결측값 탐색
diagnose(new)   # 결측치

new<-KOS[!is.na(KOS$X15세이상인구.구직기간4주.),]#결측치 제거
### mice 패키지 이용
install.packages("mice")
library(mice)
tempdata <- mice(new, maxit = 50, method = 'pmm')
summary(tempdata)
str(new)
new<- new[,-1]#날짜 제거
new$Y <- factor(new$Y) #팩터로 변환 
install.packages("Amelia")
library(Amelia)
tempdata2<-amelia(x = new, m = 5)
summary(tempdata2)

## impute된 데이터 확인하기
tempdata2$imputations[[1]]
tempdata2$imputations[[2]]
tempdata2$imputations[[1]]$Ozone
tempdata2$imputations[[2]]$Ozone


# m : 가상의 데이터셋을 몇 개 만들 것인가? (일반적으로 3~5개가 적당하며, 그 이상 만들지라도 효율성이 크게 저하되지 않음)
# ts(time series) : 시계열 정보
# cs(cross-sectional) : 분석에 포함 될 변수
library(rpart)
tree<- rpart(Y ~., data=new)
plot(tree, compress=T, margin=0.3)
text(tree, cex=1.5)



KOSPI<-data.frame(sapply(KOSPI, function(x) ifelse(is.na(x), mean(x, na.rm=TRUE), x)) )
colSums(is.na(KOSPI))
str(KOSPI)
ECONOMIC<-data.frame(sapply(ECONOMIC, function(x) ifelse(is.na(x), mean(x, na.rm=TRUE), x)) )
colSums(is.na(EXCHANGE))
EXCHANGE<-data.frame(sapply(EXCHANGE, function(x) ifelse(is.na(x), mean(x, na.rm=TRUE), x)) )
colSums(is.na(MARKET))
MARKET<-data.frame(sapply(MARKET, function(x) ifelse(is.na(x), mean(x, na.rm=TRUE), x)) )
colSums(is.na(PER))
install.packages("dlookr")

library(dlookr)
diagnose(KOSPI)
# 데이터 가공 & 관리
# 1. 변수의 중요도
install.packages("klaR")
library(klaR)

# Wilks.lambda : 집단내 분산 / 총분산
# 종속변수에 미치는 영향력에 따라 변수의 중요도를 정리 (작을수록 적합)
greedy.wilks(Y ~ ., data = KOSPI, niveau = 0.1) # 16개의 변수 선택 
greedy.wilks(KOSPI$Y ~ ., data = ECONOMIC, niveau = 0.1) # 16개의 변수 선택 
#거래량, 지수종가, 신용가능종목거래량,X52주신고가종목수, X25일이평하회종목건수, 자본금, X25일이평상회종목건수, 상한종목수,회사수, 거래형성종목수, 전체종목수, 상장주식수, 배당수익율, 외국인보유시가총액, 연중최저가 종목수, X52신저가 종목수 

# 데이터 분할
set.seed(1234)
inTrain <- createDataPartition(y=KOSPI$Y, p=0.7, list=FALSE)
KOSPI.train <- KOSPI[inTrain,]
KOSPI.test <- KOSPI[-inTrain,]

# 모델링

# nnet의 주요 옵션들
# size : hidden node 수 
# maxit : 반복횟수
# decay : overfitting을 피하기 위해 사용하는 weight decay parameter
# rang : Initial random weights on [-rang, rang]. default 0.5

set.seed(123)

nn_model1 <- nnet(반품여부 ~ 성별+나이+구매금액+출연자, data=cb.train, size=3, maxit=1000)
