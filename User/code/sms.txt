setwd("c:/deep")
install.packages("tm")
library(tm)

sms_raw <- read.csv("c:/deep/sms_spam1.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw$type) 
table(sms_raw$type) # 스팸과 햄의 비율을 알기 위해
sms_corpus <- VCorpus(VectorSource(sms_raw$text)) #Corpus:문자들의 집합 -> 데이터정제(소문자로 다 바꿈 등등)
#Document Term matrix  이후 분석

print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]]) #첫번째것만 볼 수 있음 
lapply(sms_corpus[1:2], as.character)
sms_corpus_clean <- tm_map(sms_corpus,content_transformer(tolower)) #대문자를 소문자로 바꿔라
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]]) #소문자로 바뀐것을 알 수 있다.
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) #숫자들을 없애라
sms_corpus_clean <- tm_map(sms_corpus_clean,
                           removeWords, stopwords())
stopwords("en") #불용어들 
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)


install.packages("SnowballC")
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)
#정제작업 끝
sms_dtm <- DocumentTermMatrix(sms_corpus_clean) #정제된 텍스트를 텀매트릭스로 만들어라

# sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
# tolower = TRUE, removeNumbers = TRUE, stopwords = TRUE, removePunctuation = TRUE, stemming = TRUE ))

sms_dtm
sms_dtm2

sms_dtm_train <- sms_dtm[1:4179, ]
sms_dtm_test <- sms_dtm[4180:5571, ]

sms_train_labels <- sms_raw[1:4179, ]$type
sms_test_labels <- sms_raw[4180:5571, ]$type

prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
#랜덤하게 쪼개졌는지 확인

install.packages("wordcloud") 
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
#50번 이상 나온 것들만 찍어라

spam <- subset(sms_raw, type == "spam")
ham <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
#스팸과 햄에 대해서 워드클라우드를 그려봐라

sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)

sms_dtm_freq_train<- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]

convert_counts <- function(x) { x <- ifelse(x > 0, "Yes", "No") }
#단어가 나오면  yes 아니면 no

sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)

install.packages("e1071") 
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)

sms_test_pred <- predict(sms_classifier, sms_test)

library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))

sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)

sms_test_pred2 <- predict(sms_classifier2, sms_test)

CrossTable(sms_test_pred2, sms_test_labels,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))
